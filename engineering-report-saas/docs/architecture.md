# 系统架构设计文档

**版本**：1.1  
**日期**：2026-02-25  
**状态**：已完成

---

## 1. 系统架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                         用户端                                  │
│              （Web端）                                          │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                      接入层                                     │
│            （CDN加速 / HTTPS / WAF防护）                        │
│            域名：articly.chat                                   │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                      应用层 (Next.js)                           │
│                                                                   │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │   用户模块   │  │   对话模块   │  │   AI模块     │              │
│  │  注册/登录   │  │  对话交互    │  │  多模型调用  │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                      AI 服务层                                  │
│                     硅基流动(SiliconFlow)                        │
│                                                                   │
│   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐         │
│   │MiniMax 2.5   │  │DeepSeek V3   │  │  GLM-5       │         │
│   │  (主力)       │  │  (备用1)     │  │  (备用2)     │         │
│   └──────────────┘  └──────────────┘  └──────────────┘         │
│                                                                   │
│   ┌──────────────┐                                             │
│   │ Qwen 3.5     │                                             │
│   │  (备用3)     │                                             │
│   └──────────────┘                                             │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                      数据层                                     │
│                                                                   │
│   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐         │
│   │  PostgreSQL  │  │    Redis     │  │   对象存储    │         │
│   │   (Supabase) │  │   (缓存)     │  │  (文件/图片)  │         │
│   └──────────────┘  └──────────────┘  └──────────────┘         │
└─────────────────────────────────────────────────────────────────┘
```

---

## 2. 技术选型

| 层级 | 技术方案 | 说明 |
|------|----------|------|
| **前端** | React + Next.js | 前后端一体，部署简单 |
| **后端** | Next.js API Routes | 前后端同一仓库 |
| **数据库** | PostgreSQL (Supabase) | 免费额度够用 |
| **AI模型** | MiniMax 2.5 / DeepSeek V3 / GLM-5 / Qwen 3.5 | 硅基流动API |
| **部署** | Vercel (MVP阶段) | 免费，自带CDN |

---

## 3. Multi-Agent 装配式架构

### 设计理念
采用模块化、装配式设计，参考 OpenClaw 的 Agent 架构思路：
- 接口标准化：所有 Agent 使用统一的通信协议
- 可插拔：随时替换/升级单个 Agent
- 可扩展：新增 Agent 不影响现有系统

### Agent 清单（MVP阶段）

| Agent | 数量 | 职责 |
|-------|------|------|
| 对话Agent | 1 | 主对话，引导用户，协调其他Agent |
| 信息提取Agent | 1 | 提取关键信息（名称、地点、投资等） |
| 生成Agent | 1 | 分章节生成报告内容 |
| 整合Agent | 1 | 把各章节整合成完整报告 |
| 格式Agent | 1 | Markdown转PDF |

### 工作流程
1. 用户对话 → 对话Agent接收
2. 信息提取Agent → 提取关键信息
3. 生成Agent → 分章节生成
4. 整合Agent → 汇总成完整报告
5. 格式Agent → 转换为PDF

### 扩展路线
- V1.0: + 资料处理Agent（处理上传的图片、Excel）
- V1.5: + 文本库增强Agent（提高准确性）
- V2.0: + 专业领域Agent（财务分析、环保评估等）

---

## 4. AI模型配置

### 模型列表（按优先级）

| 优先级 | 模型 | 状态 | 说明 |
|--------|------|------|------|
| 1 | MiniMax 2.5 (mx-T2-2002203042) | ✅ 主力 | 主用模型 |
| 2 | DeepSeek V3 | ✅ 备用 | 自动切换 |
| 3 | GLM-5 | ✅ 备用 | 自动切换 |
| 4 | Qwen 3.5 | ✅ 备用 | 自动切换 |

### 自动切换机制
- API调用按优先级顺序尝试
- 当前一个模型失败时，自动切换到下一个
- 保证服务高可用性

---

*本文档将根据讨论持续更新*